# âš¡ BizClaw

> **Háº¡ táº§ng AI Assistant nhanh, module hoÃ¡ â€” viáº¿t hoÃ n toÃ n báº±ng Rust.**

BizClaw lÃ  ná»n táº£ng AI Agent kiáº¿n trÃºc trait-driven, cÃ³ thá»ƒ cháº¡y **má»i nÆ¡i** â€” tá»« Raspberry Pi Ä‘áº¿n cloud server. Há»— trá»£ nhiá»u LLM provider, kÃªnh giao tiáº¿p, vÃ  cÃ´ng cá»¥ thÃ´ng qua kiáº¿n trÃºc thá»‘ng nháº¥t, hoÃ¡n Ä‘á»•i Ä‘Æ°á»£c.

[![Rust](https://img.shields.io/badge/Rust-100%25-orange?logo=rust)](https://www.rust-lang.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-45%20passing-brightgreen)]()
[![LoC](https://img.shields.io/badge/lines-8.7k%20Rust-informational)]()
[![Coverage](https://img.shields.io/badge/crates-11%2F11%20tested-success)]()

---

## ï¿½ğŸ‡³ Tiáº¿ng Viá»‡t

### ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- **ğŸ§  Brain Engine (Bá»™ nÃ£o cá»¥c bá»™)** â€” Cháº¡y model LLaMA ngay trÃªn mÃ¡y qua GGUF, mmap, quantization (Q4_0/Q8_0), KV Cache, Forward Pass Ä‘áº§y Ä‘á»§, SIMD acceleration
- **ğŸ”Œ Äa nhÃ  cung cáº¥p AI** â€” OpenAI, Anthropic Claude, Ollama, llama.cpp, OpenRouter, hoáº·c báº¥t ká»³ server tÆ°Æ¡ng thÃ­ch OpenAI
- **ğŸ’¬ Äa kÃªnh giao tiáº¿p** â€” CLI, Zalo (Personal + OA + WebSocket), Telegram Bot (polling), Discord Bot (Gateway WS), Webhook
- **ğŸ› ï¸ Tool Calling** â€” Thá»±c thi shell, thao tÃ¡c file, registry Ä‘á»™ng vá»›i arg validation
- **ğŸ”’ Báº£o máº­t** â€” Danh sÃ¡ch lá»‡nh cho phÃ©p, giá»›i háº¡n Ä‘Æ°á»ng dáº«n, sandbox, mÃ£ hoÃ¡ AES-256, HMAC-SHA256 webhook
- **ğŸ’¾ Bá»™ nhá»›** â€” SQLite, tÃ¬m kiáº¿m vector (cosine similarity), cháº¿ Ä‘á»™ táº¯t bá»™ nhá»›
- **ğŸŒ Gateway HTTP** â€” REST API + WebSocket streaming (token-by-token) dá»±a trÃªn Axum
- **âš¡ SIMD** â€” ARM NEON (Pi/Apple Silicon), x86 SSE2/AVX2 auto-dispatch
- **ğŸ“¦ Module hoÃ¡** â€” 11 crate Ä‘á»™c láº­p, 45 tests, hoÃ¡n Ä‘á»•i qua há»‡ thá»‘ng trait

### ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      bizclaw (CLI)                         â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚               â”‚   bizclaw-agent     â”‚                      â”‚
â”‚               â”‚  (Ä‘iá»u phá»‘i trung   â”‚                      â”‚
â”‚               â”‚   tÃ¢m)              â”‚                      â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚      â–¼               â–¼               â–¼                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚Providers â”‚  â”‚ Channels  â”‚  â”‚   Tools     â”‚             â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚
â”‚ â”‚ OpenAI   â”‚  â”‚   CLI     â”‚  â”‚  Shell      â”‚             â”‚
â”‚ â”‚Anthropic â”‚  â”‚  Zalo     â”‚  â”‚  File       â”‚             â”‚
â”‚ â”‚ Ollama   â”‚  â”‚ Telegram  â”‚  â”‚  (tuá»³ chá»‰nh)â”‚             â”‚
â”‚ â”‚LlamaCpp  â”‚  â”‚ Discord   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚ â”‚  Brain   â”‚  â”‚ Webhook   â”‚                               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚      â–¼               â–¼               â–¼                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚ â”‚ Memory   â”‚  â”‚ Security  â”‚  â”‚  Gateway    â”‚            â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
â”‚ â”‚ SQLite   â”‚  â”‚Allowlist  â”‚  â”‚ Axum HTTP   â”‚            â”‚
â”‚ â”‚ Vector   â”‚  â”‚ Sandbox   â”‚  â”‚ WebSocket   â”‚            â”‚
â”‚ â”‚  NoOp    â”‚  â”‚ AES-256   â”‚  â”‚ REST API    â”‚            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                     â–¼                                     â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚            â”‚  bizclaw-brain   â”‚                           â”‚
â”‚            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                           â”‚
â”‚            â”‚ GGUF v3 Parser   â”‚                           â”‚
â”‚            â”‚ Forward Pass     â”‚                           â”‚
â”‚            â”‚ BPE Tokenizer    â”‚                           â”‚
â”‚            â”‚ Attention + GQA  â”‚                           â”‚
â”‚            â”‚ KV Cache         â”‚                           â”‚
â”‚            â”‚ Quantization     â”‚                           â”‚
â”‚            â”‚ SIMD / Rayon     â”‚                           â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ Báº¯t Ä‘áº§u nhanh

```bash
# Clone vÃ  build
git clone https://github.com/nguyenduchoai/bizclaw.git
cd bizclaw
cargo build --release

# Cháº¡y vá»›i OpenAI
export OPENAI_API_KEY="sk-..."
./target/release/bizclaw chat

# Cháº¡y vá»›i Ollama (model cá»¥c bá»™)
ollama serve &
ollama pull llama3.2
./target/release/bizclaw chat --provider ollama --model llama3.2

# Cháº¡y vá»›i Anthropic Claude
export ANTHROPIC_API_KEY="sk-ant-..."
./target/release/bizclaw chat --provider anthropic

# Táº£i model cho Brain Engine
./target/release/bizclaw brain download tinyllama-1.1b
./target/release/bizclaw brain test "Xin chÃ o!"

# Xem thÃ´ng tin há»‡ thá»‘ng
./target/release/bizclaw info
```

### âš™ï¸ Cáº¥u hÃ¬nh

File cáº¥u hÃ¬nh táº¡i `~/.bizclaw/config.toml`:

```toml
default_provider = "openai"
default_model = "gpt-4o-mini"
default_temperature = 0.7

[identity]
name = "BizClaw"
persona = "Trá»£ lÃ½ AI thÃ´ng minh"
system_prompt = "Báº¡n lÃ  BizClaw, trá»£ lÃ½ AI nhanh vÃ  cÃ³ nÄƒng lá»±c."

[brain]
enabled = true
model_path = "~/.bizclaw/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
threads = 4
temperature = 0.7

[memory]
backend = "sqlite"
auto_save = true

[gateway]
enabled = false
host = "127.0.0.1"
port = 3000

[autonomy]
level = "supervised"
allowed_commands = ["ls", "cat", "echo", "pwd", "find", "grep"]
```

### ğŸ“¦ Báº£ng Crate

| Crate | MÃ´ táº£ | Tests | Tráº¡ng thÃ¡i |
|-------|--------|-------|------------|
| `bizclaw-core` | Traits, types, config, errors | 11 | âœ… HoÃ n thÃ nh |
| `bizclaw-brain` | GGUF + Forward Pass + SIMD | 12 | âœ… HoÃ n thÃ nh |
| `bizclaw-providers` | OpenAI, Anthropic, Ollama, LlamaCpp, Brain, Custom | â€” | âœ… HoÃ n thÃ nh |
| `bizclaw-channels` | CLI, Zalo, Telegram (polling), Discord (GW), Webhook | 2 | âœ… HoÃ n thÃ nh |
| `bizclaw-memory` | SQLite, Vector, NoOp backends | 3 | âœ… HoÃ n thÃ nh |
| `bizclaw-tools` | Shell, File, Registry + arg validation | 5 | âœ… HoÃ n thÃ nh |
| `bizclaw-security` | Allowlist, Sandbox, AES-256 Secrets | 2 | âœ… HoÃ n thÃ nh |
| `bizclaw-agent` | Agent loop, context, tool execution | 4 | âœ… HoÃ n thÃ nh |
| `bizclaw-gateway` | Axum HTTP + WebSocket streaming | 4 | âœ… HoÃ n thÃ nh |
| `bizclaw-runtime` | Native process adapter | 2 | âœ… HoÃ n thÃ nh |

### ğŸ§  Brain Engine â€” Chi tiáº¿t

| ThÃ nh pháº§n | MÃ´ táº£ |
|------------|--------|
| **GGUF v3 Parser** | Äá»c metadata + tensor index Ä‘áº§y Ä‘á»§ |
| **Forward Pass** | LLaMA transformer: Embedding â†’ NÃ—(RMSNormâ†’MHA+GQAâ†’SwiGLU FFN)â†’LM Head |
| **mmap Loader** | Táº£i model zero-copy (quan trá»ng cho Pi 512MB) |
| **BPE Tokenizer** | MÃ£ hoÃ¡ byte-level vá»›i merge láº·p |
| **Tensor Ops** | RMSNorm, MatMul, Softmax, SiLU, ElementWise |
| **Quantization** | Dequant Q4_0, Q8_0, F16, F32 |
| **Attention** | Scaled dot-product, GQA (Grouped Query Attention) |
| **KV Cache** | Cache key-value theo layer cho generation |
| **RoPE** | Rotary Position Embeddings multi-head |
| **Sampler** | Temperature, Top-K, Top-P, repeat penalty |
| **Thread Pool** | Rayon parallel matmul Ä‘a luá»“ng |

### ï¿½ Báº£o máº­t

| TÃ­nh nÄƒng | MÃ´ táº£ |
|-----------|--------|
| **Danh sÃ¡ch lá»‡nh** | Chá»‰ lá»‡nh Ä‘Æ°á»£c phÃ©p má»›i thá»±c thi Ä‘Æ°á»£c |
| **Giá»›i háº¡n Ä‘Æ°á»ng dáº«n** | Cháº·n truy cáº­p `~/.ssh`, `/etc`, v.v. |
| **Sandbox** | Timeout, cáº¯t output, mÃ´i trÆ°á»ng háº¡n cháº¿ |
| **AES-256 Secrets** | MÃ£ hoÃ¡ key mÃ¡y riÃªng (SHA-256 hostname+user) |
| **Webhook HMAC** | XÃ¡c minh chá»¯ kÃ½ SHA-256 cho webhook inbound |

### ğŸ—ºï¸ Lá»™ trÃ¬nh

- [x] **Phase 1** â€” Háº¡ táº§ng cá»‘t lÃµi (traits, config, errors)
- [x] **Phase 1** â€” Táº¥t cáº£ providers (OpenAI, Anthropic, Ollama, LlamaCpp, Custom)
- [x] **Phase 1** â€” CLI channel, memory, security, gateway
- [x] **Phase 2** â€” Brain engine (GGUF, tokenizer, tensor, quant, attention)
- [x] **Phase 2** â€” Brain forward pass (toÃ n bá»™ transformer pipeline)
- [x] **Phase 3** â€” Zalo client (Auth, WebSocket, Crypto, Messaging)
- [x] **Phase 3** â€” Telegram polling + Discord Gateway WebSocket
- [x] **Phase 3** â€” AES-256 encrypted secret store + Webhook channel
- [x] **Phase 3** â€” Gateway WebSocket streaming (token-by-token)
- [x] **Phase 4** â€” SIMD acceleration (NEON, SSE2, AVX2 auto-dispatch)
- [x] **Phase 4** â€” HTTP streaming model download tá»« HuggingFace
- [x] **Phase 5** â€” Zalo Personal/OA Channel wrappers
- [x] **Phase 5** â€” Tool registry + arg validation
- [x] **Phase 5** â€” 45 unit tests, 11/11 crates covered âœ…

### ğŸ“Š Thá»‘ng kÃª

| Chá»‰ sá»‘ | GiÃ¡ trá»‹ |
|--------|---------|
| **NgÃ´n ngá»¯** | 100% Rust |
| **Sá»‘ crate** | 11 (10 library + 1 binary) |
| **DÃ²ng code** | ~8,735 |
| **Test** | 45 passing (11/11 crates) |
| **Build** | 0 errors |
| **Stubs** | 0 (100% implemented) |
| **Dependencies** | tokio, axum, reqwest, serde, rusqlite, rayon, memmap2, half, aes, sha2 |

---

## ğŸ‡¬ğŸ‡§ English

### ğŸ¯ Features

- **ğŸ§  Local Brain Engine** â€” Run LLaMA models locally via GGUF with mmap, quantization, full forward pass, KV Cache, SIMD acceleration
- **ğŸ”Œ Multi-Provider** â€” OpenAI, Anthropic Claude, Ollama, llama.cpp, OpenRouter, or any OpenAI-compatible server
- **ğŸ’¬ Multi-Channel** â€” CLI, Zalo (Personal + OA), Telegram (long polling), Discord (Gateway WS), Webhook (HMAC)
- **ğŸ› ï¸ Tool Calling** â€” Shell execution, file operations, dynamic registry with arg validation
- **ğŸ”’ Security** â€” Command allowlists, path restrictions, sandbox, AES-256 secrets, HMAC-SHA256 webhook verification
- **ğŸ’¾ Memory** â€” SQLite persistence, in-memory vector search (cosine similarity), no-op mode
- **ğŸŒ HTTP Gateway** â€” REST API + WebSocket streaming (chat_start â†’ chunks â†’ chat_done)
- **âš¡ SIMD** â€” ARM NEON (Pi/Apple Silicon), x86 SSE2/AVX2 auto-dispatch
- **ğŸ“¦ Modular** â€” 11 crates, 45 tests, 100% implemented, swap via traits

### ğŸš€ Quick Start

```bash
# Clone and build
git clone https://github.com/nguyenduchoai/bizclaw.git
cd bizclaw
cargo build --release

# Run with OpenAI
export OPENAI_API_KEY="sk-..."
./target/release/bizclaw chat

# Run with Ollama (local model)
ollama serve &
ollama pull llama3.2
./target/release/bizclaw chat --provider ollama --model llama3.2

# Run with Anthropic Claude
export ANTHROPIC_API_KEY="sk-ant-..."
./target/release/bizclaw chat --provider anthropic

# Download model for Brain Engine
./target/release/bizclaw brain download tinyllama-1.1b
./target/release/bizclaw brain test "Hello!"

# System info
./target/release/bizclaw info
```

### âš™ï¸ Configuration

TOML config at `~/.bizclaw/config.toml`:

```toml
default_provider = "openai"
default_model = "gpt-4o-mini"
default_temperature = 0.7

[identity]
name = "BizClaw"
persona = "A helpful AI assistant"
system_prompt = "You are BizClaw, a fast and capable AI assistant."

[brain]
enabled = true
model_path = "~/.bizclaw/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
threads = 4
temperature = 0.7

[memory]
backend = "sqlite"
auto_save = true

[gateway]
enabled = false
host = "127.0.0.1"
port = 3000

[autonomy]
level = "supervised"
allowed_commands = ["ls", "cat", "echo", "pwd", "find", "grep"]
```

### ğŸ“¦ Crate Map

| Crate | Description | Status |
|-------|-------------|--------|
| `bizclaw-core` | Traits, types, config, errors | âœ… Complete |
| `bizclaw-brain` | Local GGUF inference engine + Forward Pass | âœ… Complete |
| `bizclaw-providers` | OpenAI, Anthropic, Ollama, LlamaCpp, Brain, Custom | âœ… Complete |
| `bizclaw-channels` | CLI, Zalo (Auth/WS/Crypto), Telegram, Discord | âœ… Complete |
| `bizclaw-memory` | SQLite, Vector, NoOp backends | âœ… Complete |
| `bizclaw-tools` | Shell, File tools + registry | âœ… Complete |
| `bizclaw-security` | Allowlist, Sandbox, AES-256 Secrets | âœ… Complete |
| `bizclaw-agent` | Agent loop, context, tool execution | âœ… Complete |
| `bizclaw-gateway` | Axum HTTP + WebSocket API | âœ… Complete |
| `bizclaw-runtime` | Native process adapter | âœ… Complete |

### ğŸ§  Brain Engine

| Component | Description |
|-----------|-------------|
| **GGUF v3 Parser** | Full metadata + tensor index parsing |
| **Forward Pass** | LLaMA transformer: Embedding â†’ NÃ—(RMSNormâ†’MHA+GQAâ†’SwiGLU FFN)â†’LM Head |
| **mmap Loader** | Zero-copy model loading (critical for Pi 512MB) |
| **BPE Tokenizer** | Byte-level encoding with iterative merges |
| **Tensor Ops** | RMSNorm, MatMul, Softmax, SiLU, ElementWise |
| **Quantization** | Q4_0, Q8_0, F16, F32 dequantization kernels |
| **Attention** | Scaled dot-product with GQA (Grouped Query Attention) |
| **KV Cache** | Per-layer key-value cache for auto-regressive generation |
| **RoPE** | Multi-head Rotary Position Embeddings |
| **Sampler** | Temperature, Top-K, Top-P, repeat penalty |
| **Thread Pool** | Rayon-based parallel matmul |

### ğŸ“¡ Gateway API

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/v1/info` | GET | System info + uptime |
| `/api/v1/config` | GET | Sanitized config |
| `/api/v1/providers` | GET | Available providers |
| `/api/v1/channels` | GET | Available channels |
| `/ws` | WS | Real-time WebSocket chat |

### ğŸ”’ Security Model

| Feature | Description |
|---------|-------------|
| **Command Allowlist** | Only whitelisted commands can be executed |
| **Path Restrictions** | Forbidden paths (e.g., `~/.ssh`) are rejected |
| **Workspace Only** | Optionally restrict to current working directory |
| **Sandbox** | Timeout, output truncation, restricted env |
| **AES-256 Secrets** | Machine-specific key encryption (SHA-256 hostname+user) |

### ğŸ—ºï¸ Roadmap

- [x] **Phase 1** â€” Core infrastructure (traits, config, error handling)
- [x] **Phase 1** â€” All providers (OpenAI, Anthropic, Ollama, LlamaCpp, Custom)
- [x] **Phase 1** â€” CLI channel, memory backends, security, gateway
- [x] **Phase 2** â€” Brain engine (GGUF, tokenizer, tensor, quant, attention)
- [x] **Phase 2** â€” Brain forward pass (full transformer pipeline)
- [x] **Phase 3** â€” Zalo client (Auth, WebSocket, Crypto, Messaging)
- [x] **Phase 3** â€” Telegram polling + Discord Gateway WebSocket
- [x] **Phase 3** â€” AES-256 encrypted secret store + Webhook channel
- [x] **Phase 3** â€” Gateway WebSocket streaming (token-by-token)
- [x] **Phase 4** â€” SIMD acceleration (NEON, SSE2, AVX2 auto-dispatch)
- [x] **Phase 4** â€” HTTP streaming model download from HuggingFace
- [x] **Phase 5** â€” Zalo Personal/OA Channel wrappers
- [x] **Phase 5** â€” Tool registry + arg validation
- [x] **Phase 5** â€” 45 unit tests, 11/11 crates covered âœ…

### ğŸ“ Project Structure

```
bizclaw/
â”œâ”€â”€ Cargo.toml                 # Workspace root
â”œâ”€â”€ src/main.rs                # CLI binary
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ bizclaw-core/          # Traits, types, config, errors
â”‚   â”œâ”€â”€ bizclaw-brain/         # Local GGUF inference engine
â”‚   â”‚   â”œâ”€â”€ forward.rs         # Full LLaMA transformer forward pass
â”‚   â”‚   â”œâ”€â”€ gguf.rs            # GGUF v3 parser
â”‚   â”‚   â”œâ”€â”€ mmap.rs            # Memory-mapped loader
â”‚   â”‚   â”œâ”€â”€ tokenizer.rs       # BPE tokenizer
â”‚   â”‚   â”œâ”€â”€ tensor.rs          # Math ops (RMSNorm, MatMul, etc.)
â”‚   â”‚   â”œâ”€â”€ quant.rs           # Quantization kernels
â”‚   â”‚   â”œâ”€â”€ attention.rs       # Scaled dot-product attention
â”‚   â”‚   â”œâ”€â”€ kv_cache.rs        # Key-value cache
â”‚   â”‚   â”œâ”€â”€ rope.rs            # Rotary position embeddings
â”‚   â”‚   â”œâ”€â”€ sampler.rs         # Token sampling
â”‚   â”‚   â””â”€â”€ model.rs           # LLaMA model params
â”‚   â”œâ”€â”€ bizclaw-providers/     # LLM provider impls
â”‚   â”‚   â”œâ”€â”€ openai.rs          # OpenAI / OpenRouter
â”‚   â”‚   â”œâ”€â”€ anthropic.rs       # Anthropic Claude
â”‚   â”‚   â”œâ”€â”€ ollama.rs          # Ollama (local/remote)
â”‚   â”‚   â”œâ”€â”€ llamacpp.rs        # llama.cpp server
â”‚   â”‚   â”œâ”€â”€ brain.rs           # Local brain with Mutex
â”‚   â”‚   â””â”€â”€ custom.rs          # Any OpenAI-compatible
â”‚   â”œâ”€â”€ bizclaw-channels/      # Communication channels
â”‚   â”‚   â”œâ”€â”€ cli.rs             # Interactive terminal
â”‚   â”‚   â”œâ”€â”€ telegram.rs        # Telegram Bot API
â”‚   â”‚   â”œâ”€â”€ discord.rs         # Discord Bot API
â”‚   â”‚   â””â”€â”€ zalo/              # Zalo Personal + OA
â”‚   â”‚       â””â”€â”€ client/        # Auth, Crypto, WS, Messaging
â”‚   â”œâ”€â”€ bizclaw-memory/        # Persistence backends
â”‚   â”œâ”€â”€ bizclaw-tools/         # Tool execution
â”‚   â”œâ”€â”€ bizclaw-security/      # Security + AES-256 secrets
â”‚   â”œâ”€â”€ bizclaw-agent/         # Agent orchestration
â”‚   â”œâ”€â”€ bizclaw-gateway/       # HTTP + WebSocket API
â”‚   â””â”€â”€ bizclaw-runtime/       # Process adapters
â””â”€â”€ plans/                     # Project plans & specs
```

### ğŸ§ª Testing

```bash
# Run all 45 tests
cargo test --workspace

# Brain engine (12 tests: tensor, SIMD, attention, quant, rope)
cargo test -p bizclaw-brain

# Core types (11 tests: config, errors, messages)
cargo test -p bizclaw-core

# Tools (5 tests: registry, arg validation)
cargo test -p bizclaw-tools

# Agent (4 tests: context management)
cargo test -p bizclaw-agent

# Gateway (4 tests: route handlers)
cargo test -p bizclaw-gateway

# Memory (3 tests: vector search)
cargo test -p bizclaw-memory

# Security (2 tests: AES-256)
cargo test -p bizclaw-security

# Channels (2 tests: Zalo crypto, webhook)
cargo test -p bizclaw-channels

# Runtime (2 tests: info, exec)
cargo test -p bizclaw-runtime
```

### ğŸ“Š Stats

| Metric | Value |
|--------|-------|
| **Language** | 100% Rust |
| **Crates** | 11 (10 library + 1 binary) |
| **Lines of Code** | ~8,735 |
| **Tests** | 45 passing (11/11 crates) |
| **Build** | 0 errors |
| **Stubs** | 0 (100% implemented) |
| **Dependencies** | tokio, axum, reqwest, serde, rusqlite, rayon, memmap2, half, aes, sha2 |

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

**BizClaw** â€” *AI nhanh, má»i nÆ¡i. / Fast AI, everywhere.*
